---
title: "Calculating the Biodiversity Intactness Index: the PREDICTS implementation"
author: "Adriana De Palma, Katia Sanchez-Ortiz, Helen R.P. Phillips and Andy Purvis"
date: '`r format(Sys.time(), "%d %B, %Y")`'
output:
  html_document:
    collapsed: no
    theme: readable
    toc: yes
    toc_depth: 4
    toc_float: yes
  github_document:
    toc: yes
    toc_depth: 4
    html_preview: FALSE
knit: (function(inputFile, encoding) {
  rmarkdown::render(inputFile, encoding = encoding,
  output_format = "all") })
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

This tutorial gives a step-by-step guide on how to calculate the Biodiversity Intactness Index (BII) using the PREDICTS database. We'll go through where to find the PREDICTS data, how we go about analysing this data and finally how to project and calculate BII, using `R`. We'll be using just a subset of the data and a very simple model to start with. 

You can explore the results from our most up-to-date global models on the Natural History Museum's [Biodiversity Trends Explorer](https://www.nhm.ac.uk/our-science/data/biodiversity-indicators/biodiversity-intactness-index-data?future-scenario=ssp2_rcp4p5_message_globiom&georegion=001&min-year=1970&max-year=2050&georegion-compare=null&show-uncertainty=true){target="_blank"}. This online tool allows users to explore historical and potential future trends in BII for different geographic units (e.g., countries, regions, global).


# About PREDICTS

<details><summary>[PREDICTS](https://www.nhm.ac.uk/our-science/research/projects/predicts.html){target="_blank"} -- Projecting Responses of Ecological Diversity In Changing Terrestrial Systems -- is a collaboration that aims to model how local terrestrial biodiversity worldwide responds to land use and related pressures, and to use such models to project how biodiversity may change under future socioeconomic scenarios. *Expand to learn more*
</summary>The PREDICTS team have collated a large database of biodiversity data from over 29,000 sites worldwide. These data have been provided by authors of over 700 separate surveys, each of which sampled biodiversity at multiple sites facing different land-use and related pressures. Although the different surveys have used a very wide range of different techniques, and focused on a wide array of different plant, fungal, invertebrate or vertebrate taxa (the database now holds data from over 50,000 species), the data from different sites within a survey are comparable, having been collected in the same way. Each site's land use and land-use intensity has been classified into a consistent set of categories, based on information in the paper or from the authors, and some other human pressures (e.g., human population density) are estimated for each site from global rasters. Details of how the database was put together -- including definitions of our land-use and use-intensity classes -- can be found in [this paper](https://onlinelibrary.wiley.com/doi/full/10.1002/ece3.1303){target="_blank"}; the first released version of the database is available from the [Natural History Museum's data portal](https://data.nhm.ac.uk/){target="_blank"}, and is described in [this paper](https://onlinelibrary.wiley.com/doi/full/10.1002/ece3.2579){target="_blank"}.

Because the database holds the original biodiversity data, statistical analysis can model a wide range of response variables (as explained in [this paper](https://www.sciencedirect.com/science/article/pii/S0065250417300284){target="_blank"}), including site-level measures of diversity (such as [within-sample species richness, rarefaction-based richness or overall organismal abundance](https://www.nature.com/articles/nature14324){target="_blank"}), [among-site differences in community composition](https://onlinelibrary.wiley.com/doi/full/10.1111/ecog.01932){target="_blank"}, or [the occurrence and/or population size of each species](https://besjournals.onlinelibrary.wiley.com/doi/full/10.1111/1365-2664.12524){target="_blank"}. Combining our data with other species-level information permits modelling of [functional and phylogenetic diversity](https://onlinelibrary.wiley.com/doi/10.1111/ddi.12638){target="_blank"} or of [a community-weighted measure of geographic range size](https://journals.plos.org/plosbiology/article?id=10.1371/journal.pbio.2006841){target="_blank"}. This walkthrough document focuses on modelling two response variables: total site-level abundance, and compositional similarity between sites.

Because the surveys in the database arise from such very different methodologies, we fit mixed-effects models with survey-level random effects, allowing us to focus on how human pressures affect the response variable while acknowledging the among-survey heterogeneity. We assume that biotic differences among matched sites with different land uses are caused by the land-use difference, a form of space-for-time substitution. Some of our models also assume that the biota at sites with minimally-used primary vegetation (and minimal levels of other pressures) approximates their pristine biota. These assumptions would not be needed if representative long-term temporal data were available.

Models can be fitted to the whole global data or to regions of particular interest (such as [tropical and subtropical forest biomes](https://www.nature.com/articles/s41598-021-98811-1){target="_blank"}). The models can be combined with detailed spatiotemporal data on the pressures [to map the projected current state of the response variable](https://onlinelibrary.wiley.com/doi/10.1111/ddi.12638){target="_blank"}, [estimate how it has changed in the past](https://www.nature.com/articles/s41598-021-98811-1){target="_blank"}, or [project its future under alternative scenarios](https://www.biorxiv.org/content/10.1101/311787v1){target="_blank"}.
</details>


# About BII
<details><summary>The Biodiversity Intactness Index (BII) was initially [proposed in 2005](https://www.nature.com/articles/nature03289){target="_blank"} as a sound, sensitive, easily understood and affordable biodiversity indicator that could easily be applied at any spatial scale and would allow for comparison with a policy target and a baseline. BII is defined as the average abundance, across a large and functionally diverse set of species, relative to their reference populations (which would ideally be populations before any impacts of modern industrial society, but which practically have to be populations in the least impacted settings available); non-native species are excluded from the calculation. *Expand to learn more*</summary>

BII became more prominent with its adoption in the [2015 revision of the Planetary Boundaries framework](https://science.sciencemag.org/content/347/6223/1259855){target="_blank"} as an interim measure of biosphere integrity. The framework proposed that reduction of average BII to below 90% across a large region such as a biome would risk large-scale disruption of the flow of ecosystem services and jeopardise sustainable development, though the paper acknowledged that the precise placement of the 'safe limit' for BII was very uncertain.

In the absence of sufficient collated biodiversity data, BII was initially [estimated](https://www.nature.com/articles/nature03289){target="_blank"} using carefully-structured expert opinion. The PREDICTS team [first estimated BII based on primary biodiversity data in 2016](https://science.sciencemag.org/content/353/6296/288){target="_blank"}, by combining two statistical models -- one of site-level organismal abundance, and one of compositional similarity to a site still having primary vegetation. The latter model was needed to account for the fact that models of overall organismal abundance do not consider turnover in species composition. Although we gave several reasons why our estimates of BII were likely to be overoptimistic, our 2016 estimates nonetheless placed the world, nearly all biomes and nearly all biodiversity hotspots below the proposed 'safe limit' for BII.

We have [continued to refine the modelling framework to improve our estimates of BII](https://www.nature.com/articles/s41598-021-98811-1){target="_blank"}. The most important improvements since the 2016 paper have been:

* Use of a more stringent baseline in models of compositional similarity. Whereas the 2016 paper used all primary vegetation sites (even those with intense human use) as the baseline land use, growth of the database and a switch to a more efficient (matrix-based) model framework have allowed us to use a more suitable baseline. Depending on the analysis, this could include only minimally-used primary vegetation as the baseline, or it could include a mixture of minimally- and lightly-used primary vegetation as well as minimally-used mature secondary vegetation.
* A more principled transformation of the compositional similarity estimates prior to modelling. Although the log-transformation used in the 2016 paper produced acceptable model diagnostics, it does not recognise the bounded nature of compositional similarity (which can range from 0 to 1). We now use a logit transformation instead, which provides more sensitive discrimination among land uses.

The estimates of BII that result from the improved framework tend to be [markedly lower than those we obtained in 2016](https://www.nature.com/articles/s41559-019-0896-0){target="_blank"}. One issue that remains to be addressed is that the land-use rasters we have been using to make spatial projections do not accurately differentiate planted from natural forest, meaning our estimates are still likely to be too high in regions with extensive planted forest. Work to address this shortcoming is underway.

More recently, we have begun to use a more conservative measure of compositional similarity. Our analyses previously used the asymmetric Jaccard Index, which considers only species identity, but not structure; for example, shifts in dominance. To account for changes in both species identity and community structure due to human activities, we have now implemented the [balanced Bray-Curtis index](https://besjournals.onlinelibrary.wiley.com/doi/10.1111/2041-210X.12693){target="_blank"}. You'll find more information about the differences between the indices below.

BII, being an indicator of the average state of local ecological communities, complements indicators based on species' global conservation status (such as the Sampled Red List Index), or on population trends (such as the Living Planet Index). These different facets of biodiversity are all important, and [can be combined to provide a roadmap towards restoring global biodiversity](https://www.nature.com/articles/s41893-018-0130-0){target="_blank"}.
</details>



# Load some packages
```{r, message=FALSE, warning=FALSE}
library(dplyr) # for easy data manipulation
library(tidyr) # ditto
library(tibble) # ditto
library(lme4) # for mixed effects models
library(car) # for logit transformation with adjustment
library(betapart) # for calculating balanced bray-curtis dissimilarity
library(terra) # for working with raster data
library(geosphere) # calculating geographic distance between sites
library(purrr) # running loops
library(furrr) # running loops in parallel
library(viridis) # figure colours for colour blindness
```

# Prepare the biodiversity data

You can download the PREDICTS data from the <a href="https://data.nhm.ac.uk/dataset/the-2016-release-of-the-predicts-database-v1-1" target="_blank">Natural History Museum data portal<a/>. If you're working in `R`, the database in `.rds` format will be much quicker to load in than the `.csv` file.

Once you've downloaded the database, read it in. We are going to filter the data for just the Americas, to make the data manipulation and modelling a bit quicker. You can calculate BII for _any_ region of the world for which there are data, although we tend to do our BII modelling on a global scale or at least across multiple biomes.

```{r}
# read in the data
diversity <- readRDS("database.rds") |>
  
  # now let's filter out just the data for the Americas
  dplyr::filter(UN_region == "Americas")

dplyr::glimpse(diversity)
```

[This paper](https://onlinelibrary.wiley.com/doi/full/10.1002/ece3.1303){target="_blank"} describes the PREDICTS database structure and content. Briefly, the database consists of a number of different sources (journal articles), `Source_ID` in the database, within which there can be multiple studies (`Study_name` and `Study_number`). Within each study, there are multiple sites (`Site_name` and `Site_number`) within blocks (`Block`). For ease, we use the combined, shorthand values for these: `SS` (`Study_number` and `Source_ID`), `SSB` (`SS` and `Block`) and `SSBS` (`SSB` and`Site_number`).

Now let's explore the data a little.
```{r}
table(diversity$Predominant_land_use, diversity$Use_intensity)
```

There's lots of data for the Americas across all land-use and intensity classes. Since we're using a simplified model for illustration purposes, we're not going to look at _all_ the use intensities here. However, we will keep _minimally-used primary vegetation_ separate, as this is the closest we have to a _pristine_ baseline.

So let's collapse down the data. Note that we're doing this purely to make the example simpler. In reality, we include multiple land use and intensity combinations, including the age class of secondary vegetation when possible.

```{r}
diversity <- diversity |>
  # make a level of Primary minimal. Everything else gets the coarse land use
  dplyr::mutate(
    LandUse = ifelse(Predominant_land_use == "Primary vegetation" & Use_intensity == "Minimal use",
                     "Primary minimal",
                     paste(Predominant_land_use)),
    
    # collapse the secondary vegetation classes together
    LandUse = ifelse(grepl("secondary", tolower(LandUse)),
                     "Secondary vegetation",
                     paste(LandUse)),
    
    # change cannot decide into NA
    LandUse = ifelse(Predominant_land_use == "Cannot decide",
                     NA, 
                     paste(LandUse)),
    
    # relevel the factor so that Primary minimal is the first level (so that it is the intercept term in models)
    LandUse = factor(LandUse),
    LandUse = relevel(LandUse, ref = "Primary minimal")
  )
```

# Calculate diversity indices

The Biodiversity Intactness Index is derived from combining two models: one of total abundance, and one of compositional similarity. We're going to calculate these diversity metrics now.

## Total Abundance

Total abundance is simply the sum of all individuals sampled at each site.

```{r}
abundance_data <- diversity |>
  
  # pull out just the abundance measures
  dplyr::filter(Diversity_metric_type == "Abundance") |>
  
  # group by SSBS (each unique value corresponds to a unique site)
  dplyr::group_by(SSBS) |>
  
  # now add up all the abundance measurements within each site
  dplyr::mutate(TotalAbundance = sum(Effort_corrected_measurement)) |>
  
  # ungroup
  dplyr::ungroup() |>
  
  # pull out unique sites
  dplyr::distinct(SSBS, .keep_all = TRUE) |>
  
  # now group by Study ID
  dplyr::group_by(SS) |>
  
  # pull out the maximum abundance for each study
  dplyr::mutate(MaxAbundance = max(TotalAbundance)) |>
  
  # ungroup
  dplyr::ungroup() |>
  
  # now rescale total abundance, so that within each study, abundance varies from 0 to 1.
  dplyr::mutate(RescaledAbundance = TotalAbundance/MaxAbundance)
```

Note that here we are using the `Effort_corrected_measurement`. For some studies, the sampling effort (but not the method) can vary slightly among sites. To account for this, we assume that abundance increases linearly with sampling effort (validated [here](https://www.nature.com/articles/srep31153){target="_blank"}) -- i.e., the abundance measurement is divided by the sampling effort so that it is transformed to abundance per unit effort. This is ok for modelling total abundance, but we can't account for how the _identity_ or _number_ of species varies with sampling effort in the same simple way. So in the next stage where species identity matters, you'll see that we're using the `Measurement` field (raw reported abundance), and will only use studies where the sampling effort does not vary among sites.

## Compositional Similarity

Up until recently, we used the _asymmetric Jaccard Index_ as our measure of compositional similarity. Essentially, we wanted to know what species are present in our baseline sites (`Primary minimal`), and then for our converted sites (all other land uses), what proportion of individuals come from species that are also found in the baseline site. We're now using a more sensitive measure of compositional similarity -- _balanced Bray-Curtis_ -- that considers changes in community structure, rather than just identity.

Let's take a look at a couple of examples to illustrate the differences between these two measures of compositional similarity.

*Example 1:*

|Site| Species A | Species B | Species C | Species D|
|:---| :---: | :---: | :---: | :---: |
|Site 1: Primary minimal | 35 | 15 | 0 | 0 |
|Site 2: Cropland | 15 | 35 | 0 | 0 |

Here we've got no new species and no changes in abundance, but the dominance structure has totally changed -- Species A is the most dominant in Site 1, but Species B is most dominant in Site 2. The _asymmetric Jaccard Index_ would say that these sites have a similarity of 1, because there are no novel species (100% of the individuals come from 'originally-present species'). Our new measure, however, would say that there is a similarity of 0.6, because there has been a change in community structure.

*Example 2:*

|Site| Species A | Species B | Species C | Species D|
|:---| :---: | :---: | :---: | :---: |
|Site 1: Primary minimal | 35 | 24 | 0 | 1 |
|Site 2: Cropland | 10 | 0 | 45 | 5 |

In this example, we've got some new species in the Cropland site, a shift in dominance (Species A is the most dominant in Primary minimal, but not in Cropland), but the same overall abundance in both sites.

When we calculate the compositional similarity using our previous measure, we get a value of 0.25 (because 15 out of the 60 individuals in Site 2 were also present in Site 1), but with our new measure, we get a value of 0.18.


Now, for every study with a `Primary minimal` site, we want to calculate this compositional similarity measure against every other site in the study. Note that this has to be done _within_ studies: it would be pointless to compare similarity between a site from a study of birds with a site from a study of bees.

Let's first set up the data we're going to use for the compositional similarity models.

```{r}
cd_data_input <- diversity |>
  
  # drop any rows with unknown LandUse
  dplyr::filter(!is.na(LandUse)) |>
  
  # pull out only the abundance data
  dplyr::filter(Diversity_metric_type == "Abundance") |>
  
  # group by Study
  dplyr::group_by(SS) |>
  
  # calculate the number of unique sampling efforts within that study
  dplyr::mutate(n_sample_effort = dplyr::n_distinct(Sampling_effort)) |>
  
  # calculate the number of unique species sampled in that study
  dplyr::mutate(n_species = dplyr::n_distinct(Taxon_name_entered)) |>
  
  # check if there are any Primary minimal sites in the dataset
  dplyr::mutate(n_primin_records = sum(LandUse == "Primary minimal")) |>
  
  # ungroup
  dplyr::ungroup() |>
  
  # now keep only the studies with one unique sampling effort
  dplyr::filter(n_sample_effort == 1) |>
  
  # and keep only studies with more than one species 
  # as these studies clearly aren't looking at assemblage-level diversity
  dplyr::filter(n_species > 1) |>
  
  # and keep only studies with at least some Primary minimal data
  dplyr::filter(n_primin_records > 0) |>
  
  # drop empty factor levels
  droplevels()
```


Now we'll set up a function to calculate compositional similarity between a single pair of sites in a study (See the previous version of this walkthrough for the function for calculating the asymmetrical Jaccard's similarity).

```{r}

get_bray <- function(s1, s2, data){
  
  sp_data <- data |>
    
    # filter out the SSBS that matches the pair of sites we're interested in
    dplyr::filter(SSBS %in% c(s1, s2)) |>
    
    # pull out the site name, species name and abundance information
    dplyr::select(SSBS, Taxon_name_entered, Measurement) |>
    
    # pivot so that each column is a species and each row is a site
    tidyr::pivot_wider(names_from = Taxon_name_entered, values_from = Measurement) |>
    
    # set the rownames to the SSBS and then remove that column
    tibble::column_to_rownames("SSBS")
  
  # if one of the sites doesn't have any individuals in it
  # i.e. the row sum is 0
  if(sum(rowSums(sp_data) == 0, na.rm = TRUE) == 1){
    # then the similarity between sites should be 0
    bray <- 0
  # if both sites have no individuals
  }else if(sum(rowSums(sp_data) == 0, na.rm = TRUE) == 2){
    # then class the similarity as NA
    bray <- NA
  # otherwise if both sites have individuals, calculate the balanced bray-curtis
  # as similarity (1-bray)
  }else{
    bray <- 1 - 
      betapart::bray.part(sp_data) |>
      purrr::pluck("bray.bal") |>
      purrr::pluck(1)
  }
  
}


```


Now that we've got the function to gather the data for the compositional similarity models, let's get the dataset. We'll first get together a vector of all the study IDs that we need to perform the calculations for.

```{r}
# get a vector of each study to loop over
studies <- cd_data_input |>
  dplyr::distinct(SS) |>
  dplyr::pull()
```

Next, get all the site comparisons for each study. We're using the `purrr:map` function here which will loop over each study in turn and perform the custom function we've specified. Note that we're using `map_dfr` because at the end, I'd like a dataframe where each row gives the pair of sites that need comparing.
```{r}
site_comparisons <- purrr::map_dfr(
  .x = studies, 
  .f = function(x){
    
    # filter out the given study
    site_data <- dplyr::filter(cd_data_input, SS == x) |>
      # pull out the SSBS and LandUse information
      dplyr::select(SSBS, LandUse) |>
      # simplify the data so we only have one row for each site
      dplyr::distinct(SSBS, .keep_all = TRUE)
    
    # pull out the sites that are Primary minimal (we only want to use comparisons with the baseline)
    baseline_sites <- site_data |>
      dplyr::filter(LandUse == "Primary minimal") |>
      dplyr::pull(SSBS)
    
    # pull out all the sites
    site_list <- site_data |>
      dplyr::pull(SSBS)
    
    # get all site x site comparisons for this study
    site_comparisons <- expand.grid(baseline_sites, site_list) |>
      
      # rename the columns so they will be what the compositional similarity function expects for ease
      dplyr::rename(s1 = Var1, s2 = Var2) |>
      
      # remove the comparisons where the same site is being compared to itself
      dplyr::filter(s1 != s2) |>
      
      # make the values characters rather than factors
      dplyr:: mutate(
        s1 = as.character(s1),
        s2 = as.character(s2),
        
        # add the full name
        contrast = paste(s1, "vs", s2, sep = "_"),
        
        # add the study id
        SS = as.character(x)
      )
    
    return(site_comparisons)
  }
)

```

For each study and set of comparisons, we need to calculate the compositional similarity. We're going to set this up to run in parallel. The following code uses the `purrr::map` functions (made to run in parallel using the `{furrr}` package), but there are other options, like `for` loops or `apply`.

```{r, cache = TRUE}
future::plan("multisession", workers = parallel::detectCores()-1)

# We're using map2 (because there are two arguments we're passing through - s1 and s2)
# and the map2_dbl because the output we want is a vector of numbers (double rather than integer format)
# so this function is going to go through each s1 and s2 in turn
# and pass them into the get_bray function
bray <- furrr::future_map2_dbl(
  .x = site_comparisons$s1,
  .y = site_comparisons$s2,
  ~get_bray(s1 = .x, s2 = .y, data = cd_data_input),
  .options = furrr::furrr_options(seed = TRUE)
)

# stop running things in parallel for now
future::plan("sequential")
```

Next we'll pull out the additional data we need (which don't require a loop), including the geographic distance between sites and the land uses.
```{r}
# for the other required information, we don't need to run loops
latlongs <- cd_data_input |>
  # for each site in the dataset
  dplyr::group_by(SSBS) |>
  # pull out the lat and long
  dplyr::summarise(
    Lat = unique(Latitude),
    Long = unique(Longitude)
  )

lus <- cd_data_input |>
  # for each site in the dataset
  dplyr::group_by(SSBS) |>
  # pull out the land use
  dplyr::summarise(lu = unique(LandUse))

```

Let's put all the data together into a dataset we can use for modelling.
```{r}
# now let's put all the data together
cd_data <- site_comparisons |>
  # add in the bray-curtis data
  # which is already in the same order as site_comparisons
  dplyr::mutate(bray = bray) |>
  # get the lat and long for s1
  dplyr::left_join(latlongs, by = c("s1" = "SSBS")) |>
  dplyr::rename(s1_lat = Lat, s1_long = Long) |>
  # get the lat and long for s2
  dplyr::left_join(latlongs, by = c("s2" = "SSBS")) |>
  dplyr::rename(s2_lat = Lat, s2_long = Long) |>
  # calculate the geographic distances between s1 and s2 sites
  dplyr::mutate(
    geog_dist = geosphere::distHaversine(
      cbind(s1_long, s1_lat), cbind(s2_long, s2_lat)
    )
  ) |>
  # get the land use for s1
  dplyr::left_join(lus, by = c("s1" = "SSBS")) |>
  dplyr::rename(s1_lu = lu) |>
  # get the land use for s2
  dplyr::left_join(lus, by = c("s2" = "SSBS")) |>
  dplyr::rename(s2_lu = lu) |>
  # create an lu_contrast column (what we'll use for modelling)
  dplyr::mutate(lu_contrast = paste(s1_lu, s2_lu, sep = "_vs_"))
```



# Run the statistical analysis

In the PREDICTS database, most of the variation in diversity is going to be between Studies -- each study looks at different species groups in different areas using different sampling methods. This has to be accounted for in the statistical analysis. We do this in a mixed effects framework: we treat studies and blocks as random effects.

## Total Abundance
Let's start with a simple model of total abundance. Note that the errors in models of ecological abundance are generally non-normal. Usually, we would deal with that by modelling abundance with an error structure, such as poisson or quasipoisson. However, in the PREDICTS database, we take quite a broad view of what counts as an 'abundance' measurement -- they are not all whole individuals so they aren't whole numbers (e.g., they might be expressed as average numbers per square metre). The `{lme4}` package doesn't really like you using a discrete error structure with continuous data. So instead, we must transform the data. Generally, a log-transformation does well, but in some cases, a square-root transformation helps to normalise the errors. *We're not going to go through model checking with you here -- this is all just to give you an idea of how to model BII, not how to do statistical analysis... Please check your residual plots etc before using models to make inferences and spatial projections!*

```{r}
# run a simple model
ab_m <- lme4::lmer(
  sqrt(RescaledAbundance) ~ LandUse + (1|SS) + (1|SSB), 
  data = abundance_data
)
summary(ab_m)
```

The model shows that all land uses except for secondary vegetation have lower total abundance than the baseline (minimally-used primary vegetation), some of them significantly so. We've just run a very simple model here, but you can add in additional human pressures (e.g., human population density).


## Compositional Similarity

Now let's do a model of compositional similarity. For compositional similarity models, we include a measure of the geographic distance beween sites. This allows us to discount _natural_ turnover in species with distance. You can also include environmental distance (we've done this previously based on Gower's dissimilarity of climatic variables). You might also want to include additional pressure variables in the compositional similarity model, such as human population density and road density. We usually do this by including the pressure at site 2 (the non-baseline site) as well as the _difference_ in pressure between site 1 and site 2.

The compositional similarity measure we use is bounded between 0 and 1 -- this means the errors will probably not be normally distributed. Although log-transformation produced models with acceptable diagnostics, it doesn't respect the boundedness of the compositional similarity measure. We've found that a logit transformation (with an adjustment to account for 0s and 1s) also gives acceptable diagnostics and is conceptually more appropriate as it does recognise the boundedness of the data.

```{r}
# there is some data manipulation we want to do before modelling
cd_data <- dplyr::mutate(
  cd_data,
  
  # logit transform the compositional similarity
  logitCS = car::logit(bray, adjust = 0.001, percents = FALSE),
  
  # log10 transform the geographic distance between sites
  log10geo = log10(geog_dist + 1),
  
  # make primary minimal-primary minimal the baseline again
  lu_contrast = factor(lu_contrast), 
  lu_contrast = relevel(lu_contrast, ref = "Primary minimal_vs_Primary minimal")
)



# Model compositional similarity as a function of the land-use contrast and the geographic distance between sites
cd_m <- lme4::lmer(
  logitCS ~ lu_contrast + log10geo + (1|SS) + (1|s2), 
  data = cd_data
)
summary(cd_m)
```

Note that you can't trust the significance values of these compositional similarity values. The same site goes into multiple comparisons in the model (each Primary minimal site is compared to all other sites in the study), which will inflate the p-values. We've added in a random intercept for site 2 (`s2`) to try to account for this, but really if you want to look at significance values, you'll need to use permutation tests in order to see which effects are significant. We're not going to do that here because they can take a while.


# Projecting the model

Now we have one model (`ab_m`) telling us how land-use change influences the total abundance of species and one model (`cs_m`) that tells how similar the community structure is. Multiplying these together gives us the BII: the intactness of nature in the system. We do this by projecting abundance and compositional similarity onto rasters of pressure data, and then multiplying the two output maps together. You can use python to project predicts-style models ([See here for the code](https://github.com/ricardog/raster-project){target="_blank"}), but let's do it using R so you can see step-by-step exactly what's happening. 


## Model predictions

First of all, let's use the models to predict the abundance and compositional similarity in each land-use class, ignoring the impact of random effects (see `help(predict.merMod)` for more details on this).

```{r}
# let's start with the abundance model

# set up a dataframe with all the levels you want to predict diversity for
# so all the land-use classes in your model must be in here
newdata_ab <- data.frame(LandUse = levels(abundance_data$LandUse)) |>
  
  # now calculate the predicted diversity for each of these land-use levels
  # setting re.form = NA means random effect variance is ignored
  # then square the predictions (because we modelled the square root of abundance, so we have to back-transform it to get the real predicted values)
  dplyr::mutate(ab_m_preds = predict(ab_m, dplyr::across(dplyr::everything()), re.form = NA) ^ 2)


# now the compositional similarity model

# set up a function to calculate the inverse logit of the adjusted logit function we used
# where f is the value to be back-transformed and a is the adjustment value used for the transformation
inv_logit <- function(f, a){
  a <- (1-2*a)
  (a*(1+exp(f))+(exp(f)-1))/(2*a*(1+exp(f)))
}

# once again, set up the dataframe with all the levels you want to predict diversity for
# because we had an extra fixed effect in this model (log10geo), we also have to set a baseline level for this
# We're interested in the compositional similarity when we discount natural turnover, so we want to set this to a static value. We'll use 0 here, but we can also set it to the median geographic distance in the original data or any other meaningful level.
newdata_cd <- data.frame(
  lu_contrast = levels(cd_data$lu_contrast),
  log10geo = 0
) |>
  dplyr::mutate(
    cd_m_preds = predict(cd_m, dplyr::across(dplyr::everything()), re.form = NA) |>
      inv_logit(a = 0.001)
  )
```

It's these _predicted_ values (`ab_m_preds` and `cd_m_preds`) that we're going to use. We will multiply the predicted abundance and compositional similarity in each land-use class with the area of the cell in that land-use class. However, because we have a mixed effects model, the _absolute_ values are somewhat meaningless. Instead, we care about the _relative_ values -- what is the abundance or compositional similarity _relative_ to what we'd find if the whole landscape was still minimally-used primary vegetation. So once we have the predictions, we divide by the reference value (the predicted abundance or compositional similarity if the whole cell was minimally-used primary vegetation).

## Gather land-use rasters
You can use any land-use data you like, but many land-use maps don't have classes that map easily onto the definitions used by PREDICTS. Notable exceptions are land-use maps developed for the Representative Concentration Pathways (<a href="http://luh.umd.edu/data.shtml#LUH1_Data" target="_blank">LUH1<a/>) -- because PREDICTS land-use classes were designed with these maps in mind -- and the derived fine-resolution product developed by <a href="https://data.csiro.au/dap/landingpage?pid=csiro:15276&v=3&d=true" target="_blank">CSIRO<a/>.

We're just going to simulate some rasters here for ease.

We've got seven land-use classes. Imagine we have seven rasters, one for each land-use class, and the cell value is the proportion of the cell assigned to that land-use class. We'll generate some random numbers for each of the land uses -- let's make it mostly cropland, with a fair chunk of pasture and secondary vegetation, with just patches of natural land and urban areas.
```{r}
# generate a dataframe with random numbers for the cell values for each land-use class
lus <- data.frame(
  pri_min = rnorm(25, mean = 50, sd = 25),
  pri = rnorm(25, mean = 100, sd = 25),
  plant = rnorm(25, mean = 100, sd = 25),
  sec = rnorm(25, mean = 300, sd = 25),
  crop = rnorm(25, mean = 1000, sd = 25),
  pas = rnorm(25, mean = 400, sd = 25),
  urb = rnorm(25, mean = 50, sd = 25)
)

# let's artificially make the first cell dominated by urban land and the last cell dominated by minimally-used primary vegetation
lus$urb[1] <- 2000
lus$pri_min[25] <- 2000

lus <- lus |>
  # calculate the row totals
  dplyr::mutate(tot = rowSums(dplyr::across(dplyr::everything()))) |>
  
  # now, for each land use, divide the value by the rowsum
  # this will give us the proportion of each land use in each cell
  dplyr::transmute_at(1:7, list(~ ./tot))

# double check that the proportions of each land use sum to 1 (accounting for rounding errors)
all(zapsmall(rowSums(lus)) == 1)

```

Now turn each land use into its own 5 $\times$ 5 raster.

```{r}
# for each column of lus (i.e., each land use)
for(i in 1:ncol(lus)){
  
  # take the column and turn it into a 5 x 5 matrix
  ras <- matrix(lus[ , i], nrow = 5, ncol = 5) |>
    # turn that into a raster
    terra::rast()
  
  # come up with a name for the object to hold that raster
  nm <- paste(names(lus)[i], "raster", sep = "_")
  
  # and assign the raster to that name
  assign(x = nm, value = ras)
  
}
```

For example, here's the raster showing the amount of urban land in each cell:
```{r}

terra::plot(urb_raster, col = viridis::viridis(20))

```


## Spatial projections of BII

Calculate the output rasters for abundance (`ab_raster`) and compositional similarity (`cd_raster`) by multiplying the predictions for each land-use class by the amount of that land-use class in the cell.

```{r}
ab_raster <- (newdata_ab$ab_m_preds[newdata_ab$LandUse == 'Primary minimal'] * pri_min_raster + 
  newdata_ab$ab_m_preds[newdata_ab$LandUse == 'Primary vegetation'] * pri_raster + 
  newdata_ab$ab_m_preds[newdata_ab$LandUse == 'Plantation forest'] * plant_raster +
  newdata_ab$ab_m_preds[newdata_ab$LandUse == 'Secondary vegetation'] * sec_raster +
  newdata_ab$ab_m_preds[newdata_ab$LandUse == 'Cropland'] * crop_raster +
  newdata_ab$ab_m_preds[newdata_ab$LandUse == 'Pasture'] * pas_raster +
  newdata_ab$ab_m_preds[newdata_ab$LandUse == 'Urban'] * urb_raster) /
  
  # divide by the reference value
  newdata_ab$ab_m_preds[newdata_ab$LandUse == 'Primary minimal']


cd_raster <- (newdata_cd$cd_m_preds[newdata_cd$lu_contrast == 'Primary minimal_vs_Primary minimal'] * pri_min_raster + 
  newdata_cd$cd_m_preds[newdata_cd$lu_contrast == 'Primary minimal_vs_Primary vegetation'] * pri_raster + 
  newdata_cd$cd_m_preds[newdata_cd$lu_contrast == 'Primary minimal_vs_Plantation forest'] * plant_raster + 
  newdata_cd$cd_m_preds[newdata_cd$lu_contrast == 'Primary minimal_vs_Secondary vegetation'] * sec_raster +
  newdata_cd$cd_m_preds[newdata_cd$lu_contrast == 'Primary minimal_vs_Cropland'] * crop_raster +
  newdata_cd$cd_m_preds[newdata_cd$lu_contrast == 'Primary minimal_vs_Pasture'] * pas_raster +
  newdata_cd$cd_m_preds[newdata_cd$lu_contrast == 'Primary minimal_vs_Urban'] * urb_raster) /
  
  # divide by the reference value
  newdata_cd$cd_m_preds[newdata_cd$lu_contrast == 'Primary minimal_vs_Primary minimal']
```

The final step is to multiply the abundance and compositional similarity rasters together. We'll also multiply the values by 100 so that BII is expressed as a percentage rather than a proportion.

```{r}
bii <- ab_raster * cd_raster
terra::plot(bii * 100, col = viridis::viridis(20))

```


Once you have your map of BII, you can calculate the average value across any spatial scale. The average BII across this map is `r terra::global(bii*100, "mean") |> round(digits = 2) |> dplyr::pull(mean)`.

And that is it. A quick walkthrough of how we use the PREDICTS database to model and project the Biodiversity Intactness Index.

# Extensions

- The model framework is pretty flexible, so you can incorporate additional human pressures (like human population density and road density) into the statistical models of both abundance and compositional similarity.
- If you'd like to _weight_ your maps of BII, you can also multiply the outputs by additional layers, such as NPP, to give more weight to naturally more productive or more diverse areas. 
- If you have pressure data across time as well as space, you can look at temporal changes in BII (assuming that responses to pressures are the same across these time periods).

## Validation
Four approaches have been used to validate PREDICTS' models and estimates of BII.

1. Jack-knifing has been used to assess whether any parameter estimates are unduly sensitive to particular individual studies (e.g. [this paper](https://onlinelibrary.wiley.com/doi/full/10.1111/ddi.12478){target="_blank"}).
2. Cross-validation has been used to assess the robustness of parameter estimates. For example, [this paper](https://www.nature.com/articles/nature14324){target="_blank"} fitted models leaving out each biome in turn, ensuring that the global model was not driven by extreme estimates for any particular biome.
3. We have tested whether model parameters differ significantly among regions or taxonomic groups by testing for region $\times$ pressure or group $\times$ pressure interactions, e.g., [this paper](https://www.nature.com/articles/srep31153){target="_blank"} and [this paper](https://link.springer.com/article/10.1007/s10531-017-1356-2){target="_blank"}.
4. [One paper](https://zslpublications.onlinelibrary.wiley.com/doi/full/10.1111/acv.12327){target="_blank"} collected field data on birds at sites in Tanzania and Kenya, and compared an Africa-wide PREDICTS biodiversity model with a bird model based on the independent field data.

A key assumption of our method for calculating BII is that species in minimally-used primary vegetation are _native_ species. This is not always true, but we can't always identify which species are native or alien in the PREDICTS database. For island communities where we can distinguish native species from alien species, we are working to compare BII as calculated above (with an abundance model and compositional similarity model) with BII modeled as the abundance of native species only (with an abundance model of _only_ native species)([See here](https://www.biorxiv.org/content/10.1101/2019.12.16.878041v1){target="_blank"} for some of the results of this work). 

# Advantages

- BII is empirically derived from a transparent database.
- BII has been proposed as an indicator useful in assessing whether we have transgressed Planetary Boundaries.
- Because BII is an indicator of local biodiversity, you can simply average it across all the pixels in a region to get a summary of the average state of local biodiversity for that region. 

# Limitations

## Assumptions of PREDICTS
There are some inherent assumptions in PREDICTS that we've mentioned previously both in this document and in our papers. Firstly, we assume that differences in biodiversity among matched sites with different land uses are caused by the land-use difference. This is a form of space-for-time substitution. In reality, it can take centuries for the full impact of a land-use change to be seen in the ecological community; in the models we've shown you above, we've assumed that the sites are at their 'equilibrium' level of biodiversity so the full impact of land-use change has already been felt. This won't always be true. For secondary vegetation sites, we can at least _try_ to account for this by including the broad ages of secondary vegetation. Ideally, we would use time-series data to model biodiversity changes in response to land-use change, but such surveys also have their own limitations that would likely limit our ability to produce global models underpinned by geographically and taxonomically representative data ([see here](https://www.sciencedirect.com/science/article/pii/S0065250417300296){target="_blank"} for a discussion of different data types and their advantages and limitations). However, we've been working on a database and modelling framework to attempt to validate our assumptions.

Secondly, the models presented in this walkthrough assume that the biota at sites with minimally-used primary vegetation approximates their pristine biota, when in reality, truly intact land is rare. It is likely that many of the primary vegetations sites (even those that are minimally used) will have had species filtered out by past disturbances or will have experienced compositional changes due to disturbances in the surrounding areas. We can try to account for additional pressures affecting sites by including more variables in the models (e.g., human population density and distance to the nearest road or road density). However, we do not have _true_ baseline sites with which we can make biodiversity comparisons, because we don't have representative long-term data. 

## Uncertainty
Hopefully it goes without saying, but the uncertainty in the BII map will depend on its inputs, both in terms of the statistical models and the geospatial data used for projections. The higher the uncertainty in these aspects, the higher the uncertainty in the BII projections. Although land-use mapping is continually advancing, there are still limitations. So using a global map and then drilling down into a single pixel is not really advisable. Instead, the maps are more likely to be reliable when looking over broader areas and larger time steps, rather than pixel by pixel and year by year.

Note that on the Natural History Museum's [Biodiversity Trends Explorer](https://www.nhm.ac.uk/our-science/data/biodiversity-indicators/biodiversity-intactness-index-data?future-scenario=ssp2_rcp4p5_message_globiom&georegion=001&min-year=1970&max-year=2050&georegion-compare=null&show-uncertainty=true){target="_blank"}, we've used cross-validation to produce upper and lower uncertainty bounds on the projections. We have refit the models leaving one biome out in turn, and then projected BII from these models; the highest and lowest projections in the set provide some uncertainty bounds. It is important to note, however, that these bounds only include some of the many sources uncertainty (mainly stemming from geographic bias in the underlying dataset and uncertainty in model fitting), so more work still needs to be done to effectively calculate and communicate uncertainty in our projections.

## BII is a valuable metric, but isn't the only answer
BII is a measure of ecosystem intactness, but we do not expect it to be used in isolation. There are myriad biodiversity metrics and indices out there, and which one you use will depend on what is most important/interesting/relevant to you and your system. [BII is just one metric, but can complement others](https://www.nature.com/articles/s41893-018-0130-0){target="_blank"}, such as indicators based on extinction risk and population decline.


# R Info
```{r}
utils::sessionInfo()
```


# Acknowledgements
Many thanks to the PREDICTS team, collaborators and data contributors. In particular, we are grateful to Andrés Baselga for help deciding on a sensible compositional similarity measure and to Luca Börger for his ongoing advice on statistical modelling. This work has been supported by the Natural History Museum, the Natural Environment Research Council (NE/M014533/1), the National Council of Science & Technology of Mexico (CONACyT) and the Prince Albert II of Monaco Foundation.


